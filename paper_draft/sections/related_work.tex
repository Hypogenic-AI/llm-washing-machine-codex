\section{Related Work}\label{sec:related_work}
\para{Superposition and feature geometry.} Toy models explain why models encode many features in superposition, leading to polysemantic directions under capacity constraints \cite{elhage2022superposition}. This perspective motivates sparse bases such as \sae features for probing compound concepts.

\para{Sparse feature discovery.} \sae and dictionary-learning methods recover interpretable features from transformer activations \cite{cunningham2023sparse,anthropic2023monosemanticity}. These methods suggest a natural lens for testing whether ``washing machine'' yields a distinct sparse feature or overlaps with constituent features.

\para{Causal localization and editing.} Activation patching and causal tracing identify components responsible for specific behaviors, as in IOI circuits \cite{wang2022ioi} and factual association editing via \textsc{ROME} \cite{meng2022rome}. We adapt this style of causal intervention to test whether compound-related activations causally lift the ``machine'' logit.

\para{Neuron-level attribution.} Knowledge Neurons identifies sets of units that mediate factual predictions \cite{dai2021knowledgeneurons}. Our work sits between neuron-level attribution and sparse feature discovery by using \sae features as the unit of analysis.

\para{Positioning.} Unlike prior work that studies either sparse features or causal effects in isolation, we combine sparse overlap, causal patching, and compositionality probes on a concrete compound noun, allowing us to directly contrast feature localization with compositional representation.
