\section{Discussion}\label{sec:discussion}
\para{Interpretation.} The low overlap of top-$k$ \sae features between compound and constituents, combined with near-perfect probe reconstruction, suggests that ``washing machine'' is represented compositionally rather than by a single strong sparse feature at layer 6. The mismatch between weak overlap and strong probe performance indicates that information is present in distributed geometry even when sparse feature sets differ.

\para{Limitations.} The washing-only latent sample count is small (10), limiting overlap reliability. Causal patching uses only five template pairs and may miss subtle effects. We study a single model (\gpttwo) and one \sae layer/location, so conclusions may not generalize across depth or scale. Finally, \sae features are not guaranteed to be canonical, and different dictionaries could yield different overlap patterns.

\para{Implications.} Concept-level interventions that assume a single ``compound direction'' may be insufficient for compound nouns. Multi-feature or multi-layer edits, or interventions that explicitly model composition, are more likely to capture compound meaning in practice.

\para{Broader considerations.} Understanding compositional storage can inform safety and editing tools by clarifying when a single-feature edit is unlikely to control downstream behavior. While our study uses a narrow concept, the approach can extend to other compound nouns and idioms.
