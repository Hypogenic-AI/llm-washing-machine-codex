\section*{Abstract}
We ask whether a concrete compound noun (``washing machine'') is stored as a distinct residual-stream direction or emerges from its constituents. We analyze \gpttwo with a pretrained \sae at layer 6 (resid\_post\_mlp) and combine three probes: (i) overlap of top-$k$ \sae features across contexts, (ii) causal patching of compound activations into related prompts, and (iii) a compositionality probe that predicts compound embeddings from constituent embeddings. \wikitext provides background contexts, but it contains no literal ``washing machine'' strings, so we add synthetic compound prompts for controlled comparisons. Across top-50 features, compound--constituent Jaccard overlaps are low (0.11--0.14) and 68\% of compound features are unique, yet a ridge probe predicts compound embeddings from constituents with cosine 0.996 and much lower MSE than a head-noun baseline (5.19 vs. 12.49). Causal patching at layer 6 does not increase the logit for ``machine'' when patching ``washing machine'' into ``washing process'' (mean $\Delta$logit $-0.019 \pm 0.109$, $n=5$). These results support a compositional geometry view while offering weak evidence for a single, strong compound feature at the tested layer, suggesting that concept interventions should consider multi-feature and multi-layer composition.
