\section{Methodology}\label{sec:methodology}
\para{Problem setup.} We test whether the compound noun ``washing machine'' is represented by a distinct residual-stream feature or by composition of constituent concepts. We compare sparse feature activations, causal effects, and embedding compositionality across three context types: compound (``washing machine''), washing-only, and machine-only.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/method_overview.png}
    \caption{Method overview. We mine \wikitext contexts, extract \gpttwo activations, encode with a pretrained \sae, and evaluate overlap, causal patching, and compositional probes.}
    \label{fig:method_overview}
\end{figure}

\para{Data construction.} We use the \wikitext raw corpus (\texttt{datasets/wikitext\_2\_raw\_v1}) \cite{merity2017wikitext}. After stripping whitespace and dropping empty lines, we retain 29{,}119 non-empty lines. We extract three context sets:
(1) lines containing the exact phrase ``washing machine'' (105 contexts),
(2) lines containing ``washing'' but not ``machine'' (178 contexts), and
(3) lines containing ``machine'' but not ``washing'' (200 contexts).
Token-level latent samples are 105 (compound), 10 (washing-only), and 164 (machine-only). \Tabref{tab:data_stats} summarizes counts.

\input{tables/data_stats}

\para{Model and \sae.} We analyze \gpttwo using TransformerLens and a pretrained OpenAI \sae (v5, 32k) at layer 6, \texttt{resid\_post\_mlp}. We cache residual activations, encode them with the \sae, and aggregate latent vectors by context type.

\para{Metrics.} We compute (i) top-$k$ Jaccard overlap between compound and constituent feature sets ($k=50$), (ii) cosine similarity between mean latent vectors, (iii) causal patching logit deltas for predicting the token ``machine,'' and (iv) a ridge regression probe predicting compound embeddings from constituent embeddings, evaluated by MSE and cosine similarity. We estimate overlap uncertainty with 200 bootstrap samples.

\para{Baselines.} For probing, we compare against a \wbaseline baseline that uses only one constituent embedding. For causal patching, we use five template pairs and report mean $\Delta$logit and a two-sided $p$-value.

\para{Implementation details.} We use PyTorch 2.10.0+cu128, TransformerLens 2.15.4, and scikit-learn 1.8.0. Hyperparameters include $k=50$, ridge $\alpha=1.0$, and maximum 200 contexts. All analyses use seed 42 on a single NVIDIA RTX 3090 (24GB).
