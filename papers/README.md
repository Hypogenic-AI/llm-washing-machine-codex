# Downloaded Papers

1. **Toy Models of Superposition** (`2209.10652_toy_models_of_superposition.pdf`)
   - Authors: Nelson Elhage et al.
   - Year: 2022
   - arXiv: 2209.10652
   - Why relevant: Introduces superposition/polysemanticity framework for feature directions in neural networks.

2. **Are Representations Built from the Ground Up? An Empirical Examination of Local Composition in Language Models** (`2210.03575_are_representations_built_from_the_ground_up.pdf`)
   - Authors: Emmy Liu, Graham Neubig
   - Year: 2022
   - arXiv: 2210.03575
   - Why relevant: Empirical study of compositionality in LM representations, directly related to compound concept formation.

3. **Towards Best Practices of Activation Patching in Language Models: Metrics and Methods** (`2309.16042_best_practices_activation_patching.pdf`)
   - Authors: Fred Zhang, Neel Nanda
   - Year: 2023
   - arXiv: 2309.16042
   - Why relevant: Standardizes causal tracing/activation patching for localization of features.

4. **The Linear Representation Hypothesis and the Geometry of Large Language Models** (`2311.03658_linear_representation_hypothesis.pdf`)
   - Authors: Kiho Park, Yo Joong Choe, Victor Veitch
   - Year: 2024
   - arXiv: 2311.03658
   - Why relevant: Formalizes what it means for concepts to be represented linearly as directions.

5. **Scaling and Evaluating Sparse Autoencoders** (`2406.04093_scaling_and_evaluating_sparse_autoencoders.pdf`)
   - Authors: Leo Gao et al.
   - Year: 2024
   - arXiv: 2406.04093
   - Why relevant: Practical SAE training/scaling and evaluation metrics for feature discovery.

6. **Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2** (`2408.05147_gemma_scope.pdf`)
   - Authors: Tom Lieberum et al.
   - Year: 2024
   - arXiv: 2408.05147
   - Why relevant: Provides open SAE weights and tooling for Gemma 2 layers, enabling feature analysis.

7. **Residual Stream Analysis with Multi-Layer SAEs** (`2409.04185_residual_stream_analysis_with_multi_layer_saes.pdf`)
   - Authors: Tim Lawson et al.
   - Year: 2025
   - arXiv: 2409.04185
   - Why relevant: MLSAE approach for tracking features across layers in the residual stream.

8. **Automated Interpretability Metrics Do Not Distinguish Trained and Random Transformers** (`2501.17727_automated_interpretability_metrics_do_not_distinguish_trained_and_random_transformers.pdf`)
   - Authors: Thomas Heap et al.
   - Year: 2025
   - arXiv: 2501.17727
   - Why relevant: Cautions about SAE metrics; motivates stronger baselines.

9. **Sparse Autoencoders Do Not Find Canonical Units of Analysis** (`2502.04878_sparse_autoencoders_do_not_find_canonical_units.pdf`)
   - Authors: Patrick Leask et al.
   - Year: 2025
   - arXiv: 2502.04878
   - Why relevant: Shows SAE features are not necessarily atomic/canonical; impacts interpretation.
